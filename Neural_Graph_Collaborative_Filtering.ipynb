{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import scipy.sparse  as sp \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import torch \n",
    "from torch import nn, optim \n",
    "from torch.utils.data import Dataset, DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    seed = 42\n",
    "    num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_set = pd.read_csv('dataset/Yelp2018/total.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_test = train_test_split(d_set, train_size=0.8, random_state=args.seed)\n",
    "d_valid, d_test = train_test_split(d_test, train_size=0.5, random_state=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d_train.astype({'user_id':'category', 'business_id':'category'})\n",
    "d_valid = d_valid.astype({'user_id':'category', 'business_id':'category'})\n",
    "d_test = d_test.astype({'user_id':'category', 'business_id':'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cat = d_train.user_id.cat.categories\n",
    "b_cat = d_train.business_id.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_valid.user_id = d_valid.user_id.cat.set_categories(u_cat)\n",
    "d_valid.business_id = d_valid.business_id.cat.set_categories(b_cat)\n",
    "\n",
    "d_test.user_id = d_test.user_id.cat.set_categories(u_cat)\n",
    "d_test.business_id = d_test.business_id.cat.set_categories(b_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train.user_id = d_train.user_id.cat.codes\n",
    "d_train.business_id = d_train.business_id.cat.codes \n",
    "\n",
    "d_valid.user_id = d_valid.user_id.cat.codes\n",
    "d_valid.business_id = d_valid.business_id.cat.codes \n",
    "\n",
    "d_test.user_id = d_test.user_id.cat.codes\n",
    "d_test.business_id = d_test.business_id.cat.codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d_train.dropna()\n",
    "d_valid = d_valid.dropna()\n",
    "d_test = d_test.dropna()\n",
    "\n",
    "d_train.reset_index(drop=True, inplace=True)\n",
    "d_valid.reset_index(drop=True, inplace=True)\n",
    "d_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d_train.astype({'user_id': int, 'business_id': int})\n",
    "d_valid = d_valid.astype({'user_id': int, 'business_id': int})\n",
    "d_test = d_test.astype({'user_id': int, 'business_id': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_users = d_train.user_id.max() + 1\n",
    "args.num_items = d_train.business_id.max() + 1\n",
    "args.latent_dim = 64\n",
    "args.num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        self.in_feats = in_feats \n",
    "        self.out_feats = out_feats \n",
    "\n",
    "        self.W1 = nn.Linear(in_feats, out_feats)\n",
    "        self.W2 = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, L, SelfLoop, feats):\n",
    "        # (L+I)EW_1\n",
    "        sf_L = L + SelfLoop \n",
    "        sf_E = torch.sparse.mm(sf_L, feats)\n",
    "        left_part = self.W1(sf_E) # left part\n",
    "\n",
    "        # EL odot EW_2, odot indicates element-wise product \n",
    "        LE = torch.sparse.mm(L, feats)\n",
    "        E = torch.mul(LE, feats)\n",
    "        right_part = self.W2(E)\n",
    "\n",
    "        return left_part + right_part \n",
    "\n",
    "\n",
    "class NGCF(nn.Module):\n",
    "    def __init__(self, args, matrix):\n",
    "        self.num_users = args.num_users \n",
    "        self.num_items = args.num_items \n",
    "        self.latent_dim = args.latent_dim \n",
    "\n",
    "        self.user_emb = nn.Embedding(self.num_users, self.latent_dim)\n",
    "        self.item_emb = nn.Embedding(self.num_items, self.latent_dim)\n",
    "\n",
    "        self.num_layers = self.num_layers\n",
    "        self.selfloop = self.SelfLoop()\n",
    "        self.L = self.LaplacianMatrix()\n",
    "        self.X = self.FeatureMatrix()\n",
    "        self.I = self.SelfLoop(self.num_users + self.num_items)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.GNNLayers = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            self.GNNLayers.append(GNNLayer(self.latent_dim, self.latent_dim))\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim * self.num_layers * 2, 64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 32), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def SelfLoop(self, num):\n",
    "        idx = np.arange(0, num)\n",
    "        idx = torch.LongTensor([idx], [idx])\n",
    "        val = torch.FloatTensor([1] * num)\n",
    "        eye_matrix = torch.sparse.FloatTensor(idx, val)\n",
    "\n",
    "    def LaplacianMatrix(self, ratings):\n",
    "        iids = ratings['business_id'] + self.num_users \n",
    "        matrix = sp.coo_matrix((ratings['stars'], (ratings['user_id'], ratings['business_id'])))\n",
    "        \n",
    "        upper_matrix = sp.coo_matrix((ratings['stars'], (ratings['user_id'], iids)))\n",
    "        lower_matrix = matrix.transpose()\n",
    "        lower_matrix.resize((self.num_items, self.num_users + self.num_items))\n",
    "\n",
    "        A = torch.vstack([upper_matrix, lower_matrix])\n",
    "        row_sum = (A > 0).sum(axis=1)\n",
    "        row_sum = np.array(row_sum).flatten()\n",
    "        D = np.power(D, -0.5)\n",
    "        D = sp.diags(row_sum)\n",
    "        L = D * A * D\n",
    "        L = sp.coo_matrix(L)\n",
    "        row = L.row \n",
    "        col = L.col \n",
    "        idx = torch.LongTensor([row, col])\n",
    "        data = torch.FloatTensor(L.data)\n",
    "        SparseL = torch.sparse.FloatTensor(idx, data)\n",
    "        return SparseL \n",
    "\n",
    "    def FeatureMatrix(self):\n",
    "        uids = torch.LongTensor([i for i in range(self.num_users)]).cuda()\n",
    "        iids = torch.LongTensor([i for i in range(self.num_items)]).cuda()\n",
    "        \n",
    "        user_emb = self.user_embedding(uids)\n",
    "        item_emb = self.item_embedding(iids)\n",
    "        features = torch.cat([user_emb, item_emb], dim=0)\n",
    "        return features \n",
    "\n",
    "    def forward(self, uids, iids):\n",
    "        iids = self.num_users + iids \n",
    "\n",
    "        features = self.X \n",
    "        final_emb = features.clone()\n",
    "\n",
    "        for gnn in self.GNNLayers:\n",
    "            features = gnn(self.L, self.I, features)\n",
    "            features = self.leakyrelu(features)\n",
    "            final_emb = torch.concat([final_emb, features],dim=-1)\n",
    "\n",
    "        user_emb = final_emb[uids]\n",
    "        item_emb = final_emb[iids]\n",
    "\n",
    "        inputs = torch.concat([user_emb, item_emb], dim=-1)\n",
    "        outs = self.fc_layer(inputs)\n",
    "        return outs.flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
